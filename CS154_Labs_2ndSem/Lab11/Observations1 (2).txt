Here we introduce the concept of memoization to exhibit it's usefulness in "pruning" the branches of a recursion tree by just expending a few extra units of memory in the form of a look_up table.
So, in the first program we define the Ackermann function, a function of a special importance in computer science, because it tests the programmer's ability to optimize away unnecessary function calls, which in other, more "tame" functions such as Fibonacci functions, merely slows the execution down, while in the case of Ackermann functions, it simply overwhelms the resources of the computer to such an extent that it becomes impossible to calculate anything but the most trivial fringe cases.
So , in the first (two) programs (one with and without the counter), we define and evaluate the Ackermann functions for some small values. Even for a value as small as "(4,5)", one is the computer gives the error "RecursionError: maximum recursion depth exceeded in comparison". Clearly, the need for memoization becomes self evident. (Note that I used the "counter" method in python which allows us to count the number of function calls).
To further reinforce our convictions, we, in 1c.py, calculate the nn=umber of times some small specific functions such as (0,0), (0,1), etc. are called. The compilation of results easily shows how so many small functions are calculated repeatedly, thus leading to loss of time.
Then, finally, memoization is implemented in 1d.py, and a lookup table is created as in 1c.py a count table had been created. 
We further confirm memoization with Fibonacci numbers in 1e.py, and check performance vis a vis time. Note however, that updating of dictionaries takes a lot of time, and thus one may sometimes even get the memoized process to be taking longer than the ordinary one! However, on running the code repeatedly, I twice obtained that the memoized code ran 102 and 81 times faster than the ordinary one.
